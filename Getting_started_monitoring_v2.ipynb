{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfLXmznlWkLu8ZVdm794lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluetarget-ai/demos/blob/main/Getting_started_monitoring_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "BlueTarget is a MLOps platform which allows ML engineer and Data Science deploy, and monitor their machine learning models. \n",
        "\n",
        "In this section we're going to see, how to create a **Monitor** for a classification model."
      ],
      "metadata": {
        "id": "D8U-yC0ZZzsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API KEY\n",
        "First of all, we need an api-key to run this tutorial. \n",
        "\n",
        "1.   Click [here](https://deploy.bluetarget.ai/signup) to create a new account.\n",
        "2.   Get your API-key clicking [here](https://deploy.bluetarget.ai/api-keys).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "470E3CZeaFw1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "o01GREyLZhZ9"
      },
      "outputs": [],
      "source": [
        "API_KEY = 'nuKS4WiD7aysMyCMu87CGV'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation \n",
        "\n",
        "You need to install BlueTarget library in order to get started with monitoring. We use sklarn to create and emulate real-time inference"
      ],
      "metadata": {
        "id": "mbjz6bxdbng1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bluetarget sklearn"
      ],
      "metadata": {
        "id": "cN_oIqrpb_8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n",
        "Let's us consider a simple model trained on iris dataset to get started with monitoring. "
      ],
      "metadata": {
        "id": "nCzCPVBFcmVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "feature_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "\n",
        "iris_frame = pd.DataFrame(iris.data, columns = feature_names)\n",
        "X = iris.data\n",
        "y = np.array([iris.target_names[i] for i in iris.target])\n",
        "\n",
        "#Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Model Training\n",
        "clf = svm.SVC(gamma='scale', kernel='rbf', probability=True)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "id": "ebGjo6QlcmE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monitor\n",
        "A monitor is the representation of a machine learning model. \n",
        "\n",
        "A monitor can be identified by your own id or auto-generated id.\n",
        "\n",
        "To learn more about monitor, click on the following [link](https://docs.deploy.bluetarget.ai/monitoring/defining-the-model-schema)\n",
        "\n",
        "\n",
        "For this example, let us to create a monitor to manage our **iris model**.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ljyCdM3ypzwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from bluetarget import Monitor, ModelSchema, MonitorPredictionType\n",
        "\n",
        "monitor = Monitor(api_key=API_KEY)\n",
        "\n",
        "MONITOR_ID = uuid.uuid4().hex\n",
        "\n",
        "monitor.create(\n",
        "    ModelSchema(\n",
        "        monitorId=MONITOR_ID,\n",
        "        name=\"Iris sklearn\",\n",
        "        description=\"sklearn model, rbf kernel\",\n",
        "        predictionType=MonitorPredictionType.CATEGORICAL,\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "rcXNN7wQqUvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monitor version\n",
        "\n",
        "A version, is the representation of each iteration of the machine learning model. For example, you have an ML in production, and you want to re-train, you should create a new monitor version, working in this way, you're able to see the performance, data drift and quality across of each iteration.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zdk0yHvKrB5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bluetarget import ModelSchemaVersion, MonitorSchemaType\n",
        "\n",
        "MONITOR_VERSION_ID = \"v1\"\n",
        "\n",
        "monitor.create_version(MONITOR_ID, ModelSchemaVersion(\n",
        "    versionId=MONITOR_VERSION_ID,\n",
        "    model_schema={\n",
        "        \"sepal_length\": MonitorSchemaType.FLOAT,\n",
        "        \"sepal_width\": MonitorSchemaType.FLOAT,\n",
        "        \"petal_length\": MonitorSchemaType.FLOAT,\n",
        "        \"petal_width\": MonitorSchemaType.FLOAT\n",
        "    }\n",
        "))"
      ],
      "metadata": {
        "id": "4BQQ0dyHrTcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logging the predictions\n",
        "\n",
        "Let us create fake inference to show how it works.\n",
        "\n",
        "For this example, we consider the following aspects.\n",
        "\n",
        "\n",
        "*   Number of predictions: **3000**.\n",
        "*   Date for predictions: **Random dates between today and 2 weeks ago**.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rg59wQZLsHKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Generate random date between today and 2 weeks ago\n",
        "def random_date():\n",
        "  current_date = datetime.now()\n",
        "  diff = random.randint(0, 14)\n",
        "  return current_date - timedelta(days=diff)\n"
      ],
      "metadata": {
        "id": "vnXzOyz2spGK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bluetarget import Prediction\n",
        "\n",
        "# Predictions\n",
        "prediction = clf.predict(X_test)\n",
        "prediction_probabilities = clf.predict_proba(X_test)\n",
        "\n",
        "# Generate fake inference to test with more data\n",
        "X_test_inc = np.repeat(X_test, 100, axis=0)\n",
        "prediction_inc = np.repeat(prediction, 100, axis=0)\n",
        "prediction_probabilities_inc = np.repeat(prediction_probabilities, 100, axis=0)\n",
        "actuals_inc = np.repeat(y_test, 100)\n",
        "\n",
        "#Store prediction id to set up the actuals\n",
        "prediction_ids = []\n",
        "\n",
        "# Let's send a batch of prediction\n",
        "prediction_batch = []\n",
        "\n",
        "CHUNK_SIZE = 300\n",
        "\n",
        "for i in range(3000):\n",
        "\n",
        "    features = {feature_names[j]: float(X_test_inc[i][j]) for j in range(4)}\n",
        "\n",
        "    probabilities = {iris.target_names[j]: float(\n",
        "        prediction_probabilities_inc[i][j]) for j in range(3)}\n",
        "    \n",
        "    prediction_id = uuid.uuid4().hex\n",
        "    prediction_ids.append(prediction_id)\n",
        "     \n",
        "    # Fill the batch array to send in chunks of 300 \n",
        "    prediction_batch.append(Prediction(\n",
        "            prediction_id=prediction_id,\n",
        "            features=features,\n",
        "            value=prediction_inc[i],\n",
        "            probabilities=probabilities,\n",
        "            created_at=random_date()\n",
        "    ))\n",
        "    \n",
        "    if len(prediction_batch) == CHUNK_SIZE:\n",
        "      monitor.log_predictions(prediction_batch)\n",
        "      prediction_batch = []"
      ],
      "metadata": {
        "id": "3JH1VQPrlaGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logging actuals\n",
        "\n",
        "Let consider that we have the ground truth for the previus inferences. The idea is that you can see, the metrics on the platform.\n",
        "\n",
        "For this example, we consider the following aspects.\n",
        "\n",
        "Number of predictions: 3000.\n",
        "Date for predictions: Random dates between today and 2 weeks ago."
      ],
      "metadata": {
        "id": "A9leQ64xyMBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_actual():\n",
        "  return iris.target_names[random.randint(0, 2)]"
      ],
      "metadata": {
        "id": "uK3TdEtB5MN6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bluetarget import PredictionActual\n",
        "\n",
        "actual_batch = []\n",
        "\n",
        "for i in range(3000):\n",
        "  \n",
        "  # Fill the batch array to send in chunks of 300 \n",
        "  actual_batch.append(PredictionActual(\n",
        "    prediction_id=prediction_ids[i],\n",
        "    value=random_actual(),\n",
        "    created_at=random_date()\n",
        "  ))\n",
        "\n",
        "  if len(actual_batch) == CHUNK_SIZE:\n",
        "    monitor.log_actuals(actual_batch)\n",
        "    actual_batch = []"
      ],
      "metadata": {
        "id": "B8ktcfF_wzjj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reference dataset\n",
        "\n",
        "\n",
        "Adding a reference dataset, typically the dataset which was used to trained your model, helps you to understand when and where your data is drifting in production.\n",
        "\n",
        "\n",
        "Let's replicate our original dataset to have more information."
      ],
      "metadata": {
        "id": "ReoMLW1OwptQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bluetarget import ColumnMapping\n",
        "\n",
        "iris_frame['target'] = [iris.target_names[i] for i in iris.target]\n",
        "iris_frame['prediction'] = clf.predict( iris.data )\n",
        "\n",
        "reference_df = pd.concat([iris_frame] * 10, ignore_index=True)\n",
        "\n",
        "monitor.add_reference_dataset(reference_df, column_mapping=ColumnMapping(\n",
        "    features=feature_names, target=\"target\", prediction=\"prediction\"\n",
        "))"
      ],
      "metadata": {
        "id": "7TsVSfgQwlgt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download inference data\n",
        "\n",
        "This section describes how a user can fetch the inference data with a python API which can be used to re-train the model on real time data."
      ],
      "metadata": {
        "id": "2j53vuZl4QrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_df = monitor.get_inference_dataset(\n",
        "    start_time=datetime(2022, 12, 1),\n",
        "    end_time=datetime(2022, 12, 14)\n",
        ")\n",
        "\n",
        "inference_df"
      ],
      "metadata": {
        "id": "QTU3VYgB4NnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}