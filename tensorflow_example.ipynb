{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zpbXAInFK_8"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow scipy requests bluetarget"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model\n",
        "\n",
        "To begin with BlueTarget, you will need to save your trained models."
      ],
      "metadata": {
        "id": "-lnx0Zlj1nE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "# Creates tensorflow model\n",
        "model = tf.keras.applications.ResNet50V2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "model.save('my_model')"
      ],
      "metadata": {
        "id": "wBeVkS6CKjkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a service\n",
        "\n",
        "Services are the core components of BlueTarget, where the serving logic is defined. Create a file name service.py with:"
      ],
      "metadata": {
        "id": "MsozRfLZ1sK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile service.py\n",
        "# service.py\n",
        "import os\n",
        "from typing import Dict, List\n",
        "from scipy.special import softmax\n",
        "import requests\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    labels: None\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self._model = None\n",
        "        self.labels = requests.get(\n",
        "            'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "        ).text.split('\\n')\n",
        "\n",
        "    def load(self):\n",
        "        self._model = keras.models.load_model(\n",
        "            f\"{os.path.dirname(__file__)}/my_model\")\n",
        "\n",
        "    def preprocess(self, image_url: str):\n",
        "        request = requests.get(image_url)\n",
        "        with tempfile.NamedTemporaryFile() as f:\n",
        "            f.write(request.content)\n",
        "            f.seek(0)\n",
        "            input_image = tf.image.decode_png(tf.io.read_file(f.name))\n",
        "        preprocessed_image = tf.keras.applications.resnet_v2.preprocess_input(\n",
        "            tf.image.resize([input_image], (224, 224))\n",
        "        )\n",
        "        return np.array(preprocessed_image)\n",
        "\n",
        "    def postprocess(self, predictions, k=5):\n",
        "        class_predictions = predictions[0]\n",
        "        class_probabilities = softmax(class_predictions)\n",
        "        top_probability_indices = class_probabilities.argsort()[\n",
        "            ::-1][:k].tolist()\n",
        "        return {self.labels[index]: 100 * class_probabilities[index].round(3) for index in top_probability_indices}\n",
        "\n",
        "    def predict(self, request: Dict) -> Dict[str, List]:\n",
        "\n",
        "        inputs = request[\"inputs\"]\n",
        "        predictions = []\n",
        "\n",
        "        for input in inputs:\n",
        "\n",
        "            input = self.preprocess(input)\n",
        "            prediction = self._model.predict(input).tolist()\n",
        "            prediction = self.postprocess(prediction)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        return {\n",
        "            \"predictions\": predictions\n",
        "        }"
      ],
      "metadata": {
        "id": "Xx-e3mGOKnH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create requirement file\n",
        "Here is where you define your model requirements, in our case we have scikit-learn pickle-mixin dependencies"
      ],
      "metadata": {
        "id": "9oBzW0jI1vIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "tensorflow==2.5.0\n",
        "scipy==1.5.4\n",
        "requests==2.27.1\n",
        "numpy==1.19.5"
      ],
      "metadata": {
        "id": "DjAhJT4uKqYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a deployment file\n",
        "\n",
        "Here you define the deployment configuration, you also can integrate this logic within your deployment pipeline.\n",
        "\n",
        "You can get your API KEY cliking [here](https://deploy.bluetarget.ai/api-keys)"
      ],
      "metadata": {
        "id": "ZYIgLmcG1yuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bluetarget import BlueTarget, Server\n",
        "\n",
        "bt = BlueTarget(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "bt.deploy(\n",
        "    model_class=\"Model\",\n",
        "    model_files=[\"service.py\", \"my_model/saved_model.pb\",\n",
        "                 \"my_model/keras_metadata.pb\",\n",
        "                 \"my_model/variables/variables.index\",\n",
        "                 \"my_model/variables/variables.data-00000-of-00001\"],\n",
        "    requirements_file=\"requirements.txt\",\n",
        "    serverId=Server.standard_small\n",
        ")"
      ],
      "metadata": {
        "id": "MM9OJhX9KtWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}